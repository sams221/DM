{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49664982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donn√©es et standardisation...\n",
      "\n",
      "==================================================\n",
      "  R√âSULTATS DE CLASSIFICATION k-NN VECTORIS√â (k=5)\n",
      "==================================================\n",
      "Pr√©cision globale (Accuracy): 92.35%\n",
      "\n",
      "Rapport de Classification:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Non-Feu (0)       0.96      0.93      0.94      6189\n",
      "     Feu (1)       0.84      0.92      0.88      2652\n",
      "\n",
      "    accuracy                           0.92      8841\n",
      "   macro avg       0.90      0.92      0.91      8841\n",
      "weighted avg       0.93      0.92      0.92      8841\n",
      "\n",
      "\n",
      "‚úÖ Matrice de Confusion sauvegard√©e : C:\\Users\\hp\\Desktop\\TPs\\DataMining\\Results\\plots_knn\\knn_k5_confusion_matrix.png\n",
      "‚úÖ Courbe ROC sauvegard√©e : C:\\Users\\hp\\Desktop\\TPs\\DataMining\\Results\\plots_knn\\knn_k5_roc_curve.png\n",
      "L'AUC (Area Under the Curve) est de : 0.9699\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, accuracy_score\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CHEMIN_FICHIER_EQUILIBRE = 'C:\\\\Users\\\\hp\\\\Desktop\\\\TPs\\\\DataMining\\\\preparing\\\\Final_Reduit30_70.csv'\n",
    "COLONNE_CIBLE = 'classe'\n",
    "K_VOISINS = 5 \n",
    "TEST_SIZE = 0.2\n",
    "DOSSIER_PLOTS = 'C:\\\\Users\\\\hp\\\\Desktop\\\\TPs\\\\DataMining\\\\Results\\\\plots_knn' \n",
    "# ---------------------\n",
    "\n",
    "class KNNVectorized:\n",
    "    # [La d√©finition compl√®te de votre classe KNNVectorized est maintenue ici]\n",
    "    \n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def _euclidean_distance(self, X_test):\n",
    "        X_test_sq = np.sum(X_test**2, axis=1, keepdims=True)\n",
    "        X_train_sq = np.sum(self.X_train**2, axis=1)\n",
    "        dot_product = np.dot(X_test, self.X_train.T)\n",
    "        sq_distances = X_test_sq + X_train_sq - 2 * dot_product\n",
    "        return np.sqrt(np.maximum(sq_distances, 0))\n",
    "\n",
    "    def _get_k_nearest_labels(self, distances_matrix):\n",
    "        k_nearest_indices = np.argsort(distances_matrix, axis=1)[:, :self.k]\n",
    "        return self.y_train[k_nearest_indices]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = np.array(X_test)\n",
    "        distances_matrix = self._euclidean_distance(X_test)\n",
    "        k_nearest_labels = self._get_k_nearest_labels(distances_matrix)\n",
    "        predictions = np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=1, arr=k_nearest_labels)\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        X_test = np.array(X_test)\n",
    "        distances_matrix = self._euclidean_distance(X_test)\n",
    "        k_nearest_labels = self._get_k_nearest_labels(distances_matrix)\n",
    "        proba_class_1 = np.mean(k_nearest_labels == 1, axis=1)\n",
    "        proba_class_0 = 1 - proba_class_1\n",
    "        return np.column_stack((proba_class_0, proba_class_1))\n",
    "\n",
    "\n",
    "# --- Fonctions de Plotting Individuelles ---\n",
    "\n",
    "def plot_and_save_confusion_matrix(y_test, y_pred, k, folder):\n",
    "    \"\"\"G√©n√®re et enregistre la matrice de confusion.\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Pr√©dit Non-Feu', 'Pr√©dit Feu'],\n",
    "                yticklabels=['R√©el Non-Feu', 'R√©el Feu'],\n",
    "                cbar=False)\n",
    "    plt.title(f'Matrice de Confusion k-NN (k={k})', fontsize=14)\n",
    "    plt.xlabel('Pr√©diction', fontsize=12)\n",
    "    plt.ylabel('R√©el', fontsize=12)\n",
    "    \n",
    "    filename = os.path.join(folder, f'knn_k{k}_confusion_matrix.png')\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close() # Ferme la figure pour lib√©rer la m√©moire\n",
    "    return filename\n",
    "\n",
    "def plot_and_save_roc_curve(y_test, y_proba, k, folder):\n",
    "    \"\"\"G√©n√®re et enregistre la courbe ROC et l'AUC.\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=3, \n",
    "             label=f'Courbe ROC (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Al√©atoire')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taux de Faux Positifs (FPR)', fontsize=12)\n",
    "    plt.ylabel('Taux de Vrais Positifs (TPR - Rappel)', fontsize=12)\n",
    "    plt.title(f'Courbe ROC k-NN (k={k})', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    filename = os.path.join(folder, f'knn_k{k}_roc_curve.png')\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close() # Ferme la figure pour lib√©rer la m√©moire\n",
    "    return filename, roc_auc\n",
    "\n",
    "\n",
    "# --- Ex√©cution Principale ---\n",
    "\n",
    "def run_knn_vectorized_and_save_plots(k=K_VOISINS):\n",
    "    try:\n",
    "        # Cr√©er le dossier pour les plots s'il n'existe pas\n",
    "        if not os.path.exists(DOSSIER_PLOTS):\n",
    "            os.makedirs(DOSSIER_PLOTS)\n",
    "            print(f\"Dossier cr√©√© : {DOSSIER_PLOTS}\")\n",
    "\n",
    "        # 1. Pr√©paration des Donn√©es\n",
    "        print(\"Chargement des donn√©es et standardisation...\")\n",
    "        df_final = pd.read_csv(CHEMIN_FICHIER_EQUILIBRE)\n",
    "        \n",
    "        X = df_final.drop(columns=[COLONNE_CIBLE, 'latitude', 'longitude'], errors='ignore') \n",
    "        y = df_final[COLONNE_CIBLE] \n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=TEST_SIZE, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # 2. Entra√Ænement et Pr√©dictions\n",
    "        \n",
    "        knn_model_vectorized = KNNVectorized(k=k)\n",
    "        knn_model_vectorized.fit(X_train_scaled, y_train.values)\n",
    "        \n",
    "        y_pred = knn_model_vectorized.predict(X_test_scaled)\n",
    "        y_proba = knn_model_vectorized.predict_proba(X_test_scaled)[:, 1] # P(Classe 1)\n",
    "\n",
    "        # 3. Affichage des M√©triques\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"  R√âSULTATS DE CLASSIFICATION k-NN VECTORIS√â (k={k})\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Pr√©cision globale (Accuracy): {accuracy_score(y_test, y_pred)*100:.2f}%\\n\")\n",
    "        print(\"Rapport de Classification:\\n\", classification_report(y_test, y_pred, target_names=['Non-Feu (0)', 'Feu (1)']))\n",
    "        \n",
    "        # 4. VISUALISATIONS ET ENREGISTREMENT INDIVIDUELS\n",
    "        \n",
    "        cm_filename = plot_and_save_confusion_matrix(y_test, y_pred, k, DOSSIER_PLOTS)\n",
    "        roc_filename, roc_auc = plot_and_save_roc_curve(y_test, y_proba, k, DOSSIER_PLOTS)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Matrice de Confusion sauvegard√©e : {cm_filename}\")\n",
    "        print(f\"‚úÖ Courbe ROC sauvegard√©e : {roc_filename}\")\n",
    "        print(f\"L'AUC (Area Under the Curve) est de : {roc_auc:.4f}\")\n",
    "        \n",
    "        # Affiche un message pour indiquer que l'ex√©cution est termin√©e\n",
    "        # Les figures individuelles sont ferm√©es (plt.close()) apr√®s l'enregistrement.\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Erreur : Le fichier d'entr√©e n'a pas √©t√© trouv√©.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Une erreur inattendue est survenue : {e}\")\n",
    "\n",
    "# Lancer la fonction\n",
    "run_knn_vectorized_and_save_plots(k=K_VOISINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a1822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donn√©es et standardisation...\n",
      "\n",
      "Calcul des m√©triques sur l'entra√Ænement...\n",
      "Calcul des m√©triques sur le test...\n",
      "\n",
      "======================================================================\n",
      "  DIAGNOSTIC D'OVERFITTING POUR k-NN (k=1)\n",
      "======================================================================\n",
      "METRIQUE             ENSEMBLE TRAIN       ENSEMBLE TEST        DIFFERENCE\n",
      "----------------------------------------------------------------------\n",
      "Accuracy Globale     99.97% (1427.39s) 93.54% (31.79s) 6.43%\n",
      "F1-score (Feu)       0.9995 0.8946 0.1049\n",
      "AUC                  0.9996 0.9292 0.0704\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "### üßê Conclusion du Diagnostic ###\n",
      "üö© ALERTE OVERFITTING : La diff√©rence d'AUC est de 0.0704 et de F1-score est de 0.1049.\n",
      "Le mod√®le est trop complexe (k est trop petit ou les donn√©es sont bruit√©es) et m√©morise l'ensemble d'entra√Ænement.\n",
      "Action recommand√©e : Augmenter la valeur de k et relancer la Grid Search.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CHEMIN_FICHIER_EQUILIBRE = 'C:\\\\Users\\\\hp\\\\Desktop\\\\TPs\\\\DataMining\\\\preparing\\\\Final_Reduit30_70.csv'\n",
    "COLONNE_CIBLE = 'classe'\n",
    "K_VOISINS = 1\n",
    "TEST_SIZE = 0.2\n",
    "# ---------------------\n",
    "\n",
    "class KNNVectorized:\n",
    "    \"\"\"Impl√©mentation du classifieur k-Nearest Neighbors (k-NN) optimis√© par vectorisation NumPy.\"\"\"\n",
    "    \n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Stocke l'ensemble d'entra√Ænement et le convertit en tableaux NumPy.\"\"\"\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def _euclidean_distance(self, X_test):\n",
    "        \"\"\"Calcule la distance Euclidienne matricielle.\"\"\"\n",
    "        X_test_sq = np.sum(X_test**2, axis=1, keepdims=True)\n",
    "        X_train_sq = np.sum(self.X_train**2, axis=1)\n",
    "        dot_product = np.dot(X_test, self.X_train.T)\n",
    "        sq_distances = X_test_sq + X_train_sq - 2 * dot_product\n",
    "        return np.sqrt(np.maximum(sq_distances, 0))\n",
    "\n",
    "    def _get_k_nearest_labels(self, distances_matrix):\n",
    "        \"\"\"Retourne les √©tiquettes des k plus proches voisins.\"\"\"\n",
    "        k_nearest_indices = np.argsort(distances_matrix, axis=1)[:, :self.k]\n",
    "        return self.y_train[k_nearest_indices]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Pr√©dit la classe de chaque point (vote majoritaire).\"\"\"\n",
    "        X_test = np.array(X_test)\n",
    "        distances_matrix = self._euclidean_distance(X_test)\n",
    "        k_nearest_labels = self._get_k_nearest_labels(distances_matrix)\n",
    "        predictions = np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=1, arr=k_nearest_labels)\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        \"\"\"Estime les probabilit√©s de la classe 1 (Feu).\"\"\"\n",
    "        X_test = np.array(X_test)\n",
    "        distances_matrix = self._euclidean_distance(X_test)\n",
    "        k_nearest_labels = self._get_k_nearest_labels(distances_matrix)\n",
    "        proba_class_1 = np.mean(k_nearest_labels == 1, axis=1)\n",
    "        proba_class_0 = 1 - proba_class_1\n",
    "        return np.column_stack((proba_class_0, proba_class_1))\n",
    "\n",
    "\n",
    "# --- Ex√©cution Principale pour le Diagnostic ---\n",
    "\n",
    "def run_knn_overfitting_diagnosis(k=K_VOISINS):\n",
    "    try:\n",
    "        # 1. Pr√©paration des Donn√©es\n",
    "        print(\"Chargement des donn√©es et standardisation...\")\n",
    "        df_final = pd.read_csv(CHEMIN_FICHIER_EQUILIBRE)\n",
    "        \n",
    "        X = df_final.drop(columns=[COLONNE_CIBLE, 'latitude', 'longitude'], errors='ignore') \n",
    "        y = df_final[COLONNE_CIBLE] \n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=TEST_SIZE, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # 2. Entra√Ænement et Pr√©dictions\n",
    "        \n",
    "        knn_model_vectorized = KNNVectorized(k=k)\n",
    "        knn_model_vectorized.fit(X_train_scaled, y_train.values)\n",
    "        \n",
    "        # --- Pr√©dictions sur l'ENSEMBLE D'ENTRA√éNEMENT (Diagnostic) ---\n",
    "        print(\"\\nCalcul des m√©triques sur l'entra√Ænement...\")\n",
    "        start_time_train = time.time()\n",
    "        y_pred_train = knn_model_vectorized.predict(X_train_scaled)\n",
    "        y_proba_train = knn_model_vectorized.predict_proba(X_train_scaled)[:, 1]\n",
    "        time_train = time.time() - start_time_train\n",
    "        \n",
    "        # --- Pr√©dictions sur l'ENSEMBLE DE TEST (Validation) ---\n",
    "        print(\"Calcul des m√©triques sur le test...\")\n",
    "        start_time_test = time.time()\n",
    "        y_pred_test = knn_model_vectorized.predict(X_test_scaled)\n",
    "        y_proba_test = knn_model_vectorized.predict_proba(X_test_scaled)[:, 1]\n",
    "        time_test = time.time() - start_time_test\n",
    "\n",
    "        \n",
    "        # 3. Calcul des M√©triques\n",
    "        \n",
    "        # M√©triques d'Entra√Ænement\n",
    "        f1_train = f1_score(y_train, y_pred_train, pos_label=1)\n",
    "        acc_train = accuracy_score(y_train, y_pred_train)\n",
    "        auc_train = auc(roc_curve(y_train, y_proba_train)[0], roc_curve(y_train, y_proba_train)[1])\n",
    "        \n",
    "        # M√©triques de Test\n",
    "        f1_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "        acc_test = accuracy_score(y_test, y_pred_test)\n",
    "        auc_test = auc(roc_curve(y_test, y_proba_test)[0], roc_curve(y_test, y_proba_test)[1])\n",
    "        \n",
    "        \n",
    "        # 4. Affichage et Conclusion\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"  DIAGNOSTIC D'OVERFITTING POUR k-NN (k={k})\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"{'METRIQUE':<20} {'ENSEMBLE TRAIN':<20} {'ENSEMBLE TEST':<20} {'DIFFERENCE':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Ligne Accuracy\n",
    "        acc_diff = acc_train - acc_test\n",
    "        print(f\"{'Accuracy Globale':<20} {acc_train*100:.2f}% ({time_train:.2f}s) {acc_test*100:.2f}% ({time_test:.2f}s) {acc_diff*100:.2f}%\")\n",
    "        \n",
    "        # Ligne F1-score (Classe 1)\n",
    "        f1_diff = f1_train - f1_test\n",
    "        print(f\"{'F1-score (Feu)':<20} {f1_train:.4f} {f1_test:.4f} {f1_diff:.4f}\")\n",
    "\n",
    "        # Ligne AUC\n",
    "        auc_diff = auc_train - auc_test\n",
    "        print(f\"{'AUC':<20} {auc_train:.4f} {auc_test:.4f} {auc_diff:.4f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # 5. Conclusion sur l'Overfitting\n",
    "        print(\"\\n### üßê Conclusion du Diagnostic ###\")\n",
    "        \n",
    "        if f1_diff > 0.05 or auc_diff > 0.03: # Seuil typique de d√©tection\n",
    "            print(f\"üö© ALERTE OVERFITTING : La diff√©rence d'AUC est de {auc_diff:.4f} et de F1-score est de {f1_diff:.4f}.\")\n",
    "            print(\"Le mod√®le est trop complexe (k est trop petit ou les donn√©es sont bruit√©es) et m√©morise l'ensemble d'entra√Ænement.\")\n",
    "            print(\"Action recommand√©e : Augmenter la valeur de k et relancer la Grid Search.\")\n",
    "        elif 0.01 <= f1_diff <= 0.05:\n",
    "             print(f\"‚ö†Ô∏è FAIBLE TENDANCE √Ä L'OVERFITTING : La performance est l√©g√®rement meilleure sur l'entra√Ænement.\")\n",
    "             print(\"Ceci est normal. L'optimisation (Grid Search) devrait trouver le meilleur compromis.\")\n",
    "        else:\n",
    "            print(\"‚úÖ BON AJUSTEMENT (GOOD FIT) : La performance sur les ensembles de Train et Test est tr√®s similaire.\")\n",
    "            print(\"Le mod√®le g√©n√©ralise bien, et la haute performance (AUC‚âà0.97) semble robuste.\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Erreur : Le fichier d'entr√©e n'a pas √©t√© trouv√©.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Une erreur inattendue est survenue : {e}\")\n",
    "\n",
    "# Lancer la fonction\n",
    "run_knn_overfitting_diagnosis(k=K_VOISINS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
